{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4fea81c8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-10T10:29:48.426222Z",
     "iopub.status.busy": "2024-08-10T10:29:48.425558Z",
     "iopub.status.idle": "2024-08-10T10:29:57.901485Z",
     "shell.execute_reply": "2024-08-10T10:29:57.900392Z"
    },
    "papermill": {
     "duration": 9.484759,
     "end_time": "2024-08-10T10:29:57.903554",
     "exception": false,
     "start_time": "2024-08-10T10:29:48.418795",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!apt-get install -y openslide-tools > /dev/null 2>&1\n",
    "!pip install openslide-python > /dev/null 2>&1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3684226e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-10T10:29:57.913257Z",
     "iopub.status.busy": "2024-08-10T10:29:57.912999Z",
     "iopub.status.idle": "2024-08-10T10:30:13.481862Z",
     "shell.execute_reply": "2024-08-10T10:30:13.481128Z"
    },
    "papermill": {
     "duration": 15.576143,
     "end_time": "2024-08-10T10:30:13.484052",
     "exception": false,
     "start_time": "2024-08-10T10:29:57.907909",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before InitGoogle() is written to STDERR\n",
      "E0000 00:00:1723285805.678129      77 common_lib.cc:798] Could not set metric server port: INVALID_ARGUMENT: Could not find SliceBuilder port 8471 in any of the 0 ports provided in `tpu_process_addresses`=\"local\"\n",
      "=== Source Location Trace: ===\n",
      "learning/45eac/tfrc/runtime/common_lib.cc:479\n",
      "D0810 10:30:05.686955669      77 config.cc:196]                        gRPC EXPERIMENT call_status_override_on_cancellation   OFF (default:OFF)\n",
      "D0810 10:30:05.686972366      77 config.cc:196]                        gRPC EXPERIMENT call_v3                                OFF (default:OFF)\n",
      "D0810 10:30:05.686976223      77 config.cc:196]                        gRPC EXPERIMENT canary_client_privacy                  ON  (default:ON)\n",
      "D0810 10:30:05.686979132      77 config.cc:196]                        gRPC EXPERIMENT capture_base_context                   ON  (default:ON)\n",
      "D0810 10:30:05.686981976      77 config.cc:196]                        gRPC EXPERIMENT client_idleness                        ON  (default:ON)\n",
      "D0810 10:30:05.686984836      77 config.cc:196]                        gRPC EXPERIMENT client_privacy                         ON  (default:ON)\n",
      "D0810 10:30:05.686987732      77 config.cc:196]                        gRPC EXPERIMENT dapper_request_wire_size               OFF (default:OFF)\n",
      "D0810 10:30:05.686990436      77 config.cc:196]                        gRPC EXPERIMENT empty_experiment                       OFF (default:OFF)\n",
      "D0810 10:30:05.686993116      77 config.cc:196]                        gRPC EXPERIMENT event_engine_client                    OFF (default:OFF)\n",
      "D0810 10:30:05.686995756      77 config.cc:196]                        gRPC EXPERIMENT event_engine_dns                       ON  (default:ON)\n",
      "D0810 10:30:05.686998453      77 config.cc:196]                        gRPC EXPERIMENT event_engine_listener                  ON  (default:ON)\n",
      "D0810 10:30:05.687001170      77 config.cc:196]                        gRPC EXPERIMENT free_large_allocator                   OFF (default:OFF)\n",
      "D0810 10:30:05.687003826      77 config.cc:196]                        gRPC EXPERIMENT google_no_envelope_resolver            OFF (default:OFF)\n",
      "D0810 10:30:05.687006501      77 config.cc:196]                        gRPC EXPERIMENT http2_stats_fix                        OFF (default:OFF)\n",
      "D0810 10:30:05.687009170      77 config.cc:196]                        gRPC EXPERIMENT keepalive_fix                          OFF (default:OFF)\n",
      "D0810 10:30:05.687011868      77 config.cc:196]                        gRPC EXPERIMENT keepalive_server_fix                   ON  (default:ON)\n",
      "D0810 10:30:05.687014701      77 config.cc:196]                        gRPC EXPERIMENT loas_do_not_prefer_rekey_next_protocol OFF (default:OFF)\n",
      "D0810 10:30:05.687017399      77 config.cc:196]                        gRPC EXPERIMENT loas_prod_to_cloud_prefer_pfs_ciphers  OFF (default:OFF)\n",
      "D0810 10:30:05.687020055      77 config.cc:196]                        gRPC EXPERIMENT monitoring_experiment                  ON  (default:ON)\n",
      "D0810 10:30:05.687022851      77 config.cc:196]                        gRPC EXPERIMENT multiping                              OFF (default:OFF)\n",
      "D0810 10:30:05.687025528      77 config.cc:196]                        gRPC EXPERIMENT peer_state_based_framing               OFF (default:OFF)\n",
      "D0810 10:30:05.687028167      77 config.cc:196]                        gRPC EXPERIMENT pending_queue_cap                      ON  (default:ON)\n",
      "D0810 10:30:05.687030890      77 config.cc:196]                        gRPC EXPERIMENT pick_first_happy_eyeballs              ON  (default:ON)\n",
      "D0810 10:30:05.687033594      77 config.cc:196]                        gRPC EXPERIMENT promise_based_client_call              OFF (default:OFF)\n",
      "D0810 10:30:05.687036221      77 config.cc:196]                        gRPC EXPERIMENT promise_based_inproc_transport         OFF (default:OFF)\n",
      "D0810 10:30:05.687038848      77 config.cc:196]                        gRPC EXPERIMENT promise_based_server_call              OFF (default:OFF)\n",
      "D0810 10:30:05.687041590      77 config.cc:196]                        gRPC EXPERIMENT registered_method_lookup_in_transport  ON  (default:ON)\n",
      "D0810 10:30:05.687044238      77 config.cc:196]                        gRPC EXPERIMENT rfc_max_concurrent_streams             ON  (default:ON)\n",
      "D0810 10:30:05.687047064      77 config.cc:196]                        gRPC EXPERIMENT round_robin_delegate_to_pick_first     ON  (default:ON)\n",
      "D0810 10:30:05.687050906      77 config.cc:196]                        gRPC EXPERIMENT rstpit                                 OFF (default:OFF)\n",
      "D0810 10:30:05.687053837      77 config.cc:196]                        gRPC EXPERIMENT schedule_cancellation_over_write       OFF (default:OFF)\n",
      "D0810 10:30:05.687056671      77 config.cc:196]                        gRPC EXPERIMENT server_privacy                         ON  (default:ON)\n",
      "D0810 10:30:05.687059558      77 config.cc:196]                        gRPC EXPERIMENT tcp_frame_size_tuning                  OFF (default:OFF)\n",
      "D0810 10:30:05.687062265      77 config.cc:196]                        gRPC EXPERIMENT tcp_rcv_lowat                          OFF (default:OFF)\n",
      "D0810 10:30:05.687064913      77 config.cc:196]                        gRPC EXPERIMENT trace_record_callops                   OFF (default:OFF)\n",
      "D0810 10:30:05.687067663      77 config.cc:196]                        gRPC EXPERIMENT unconstrained_max_quota_buffer_size    OFF (default:OFF)\n",
      "D0810 10:30:05.687070281      77 config.cc:196]                        gRPC EXPERIMENT v3_backend_metric_filter               OFF (default:OFF)\n",
      "D0810 10:30:05.687072891      77 config.cc:196]                        gRPC EXPERIMENT v3_channel_idle_filters                ON  (default:ON)\n",
      "D0810 10:30:05.687075591      77 config.cc:196]                        gRPC EXPERIMENT v3_compression_filter                  ON  (default:ON)\n",
      "D0810 10:30:05.687078253      77 config.cc:196]                        gRPC EXPERIMENT v3_server_auth_filter                  OFF (default:OFF)\n",
      "D0810 10:30:05.687080887      77 config.cc:196]                        gRPC EXPERIMENT work_serializer_clears_time_cache      OFF (default:OFF)\n",
      "D0810 10:30:05.687083476      77 config.cc:196]                        gRPC EXPERIMENT work_serializer_dispatch               OFF (default:OFF)\n",
      "D0810 10:30:05.687086141      77 config.cc:196]                        gRPC EXPERIMENT write_size_cap                         ON  (default:ON)\n",
      "D0810 10:30:05.687088821      77 config.cc:196]                        gRPC EXPERIMENT write_size_policy                      ON  (default:ON)\n",
      "D0810 10:30:05.687091549      77 config.cc:196]                        gRPC EXPERIMENT wrr_delegate_to_pick_first             ON  (default:ON)\n",
      "I0810 10:30:05.687296609      77 ev_epoll1_linux.cc:123]               grpc epoll fd: 56\n",
      "D0810 10:30:05.687311496      77 ev_posix.cc:113]                      Using polling engine: epoll1\n",
      "D0810 10:30:05.701070631      77 lb_policy_registry.cc:46]             registering LB policy factory for \"priority_experimental\"\n",
      "D0810 10:30:05.701081963      77 lb_policy_registry.cc:46]             registering LB policy factory for \"outlier_detection_experimental\"\n",
      "D0810 10:30:05.701091161      77 lb_policy_registry.cc:46]             registering LB policy factory for \"weighted_target_experimental\"\n",
      "D0810 10:30:05.701094925      77 lb_policy_registry.cc:46]             registering LB policy factory for \"pick_first\"\n",
      "D0810 10:30:05.701098548      77 lb_policy_registry.cc:46]             registering LB policy factory for \"round_robin\"\n",
      "D0810 10:30:05.701101764      77 lb_policy_registry.cc:46]             registering LB policy factory for \"weighted_round_robin\"\n",
      "D0810 10:30:05.701131509      77 lb_policy_registry.cc:46]             registering LB policy factory for \"grpclb\"\n",
      "D0810 10:30:05.701148264      77 dns_resolver_plugin.cc:43]            Using EventEngine dns resolver\n",
      "D0810 10:30:05.701165663      77 lb_policy_registry.cc:46]             registering LB policy factory for \"rls_experimental\"\n",
      "D0810 10:30:05.701188843      77 lb_policy_registry.cc:46]             registering LB policy factory for \"xds_cluster_manager_experimental\"\n",
      "D0810 10:30:05.701196985      77 lb_policy_registry.cc:46]             registering LB policy factory for \"xds_cluster_impl_experimental\"\n",
      "D0810 10:30:05.701200593      77 lb_policy_registry.cc:46]             registering LB policy factory for \"cds_experimental\"\n",
      "D0810 10:30:05.701205164      77 lb_policy_registry.cc:46]             registering LB policy factory for \"xds_override_host_experimental\"\n",
      "D0810 10:30:05.701212295      77 lb_policy_registry.cc:46]             registering LB policy factory for \"xds_wrr_locality_experimental\"\n",
      "D0810 10:30:05.701216144      77 lb_policy_registry.cc:46]             registering LB policy factory for \"ring_hash_experimental\"\n",
      "D0810 10:30:05.701219915      77 certificate_provider_registry.cc:33]  registering certificate provider factory for \"file_watcher\"\n",
      "D0810 10:30:05.701254373      77 channel_init.cc:157]                  Filter server-auth not registered, but is referenced in the after clause of grpc-server-authz when building channel stack SERVER_CHANNEL\n",
      "I0810 10:30:05.702841190      77 ev_epoll1_linux.cc:359]               grpc epoll fd: 58\n",
      "I0810 10:30:05.704036609      77 tcp_socket_utils.cc:689]              Disabling AF_INET6 sockets because ::1 is not available.\n",
      "I0810 10:30:05.708397887     231 socket_utils_common_posix.cc:452]     Disabling AF_INET6 sockets because ::1 is not available.\n",
      "I0810 10:30:05.708461834     231 socket_utils_common_posix.cc:379]     TCP_USER_TIMEOUT is available. TCP_USER_TIMEOUT will be used thereafter\n",
      "E0810 10:30:05.716944393     221 oauth2_credentials.cc:238]            oauth_fetch: UNKNOWN:C-ares status is not ARES_SUCCESS qtype=A name=metadata.google.internal. is_balancer=0: Domain name not found {created_time:\"2024-08-10T10:30:05.716920759+00:00\", grpc_status:2}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import openslide\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, Model\n",
    "import random\n",
    "import os\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fcfbd79d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-10T10:30:13.494077Z",
     "iopub.status.busy": "2024-08-10T10:30:13.493635Z",
     "iopub.status.idle": "2024-08-10T10:30:13.498573Z",
     "shell.execute_reply": "2024-08-10T10:30:13.497897Z"
    },
    "papermill": {
     "duration": 0.011539,
     "end_time": "2024-08-10T10:30:13.500115",
     "exception": false,
     "start_time": "2024-08-10T10:30:13.488576",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "import logging\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "warnings.filterwarnings('ignore')\n",
    "logging.getLogger(\"tensorflow\").setLevel(logging.ERROR)\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3abe41a3",
   "metadata": {
    "papermill": {
     "duration": 0.004139,
     "end_time": "2024-08-10T10:30:13.508170",
     "exception": false,
     "start_time": "2024-08-10T10:30:13.504031",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# EXTRACT PATCHES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a482fb5d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-10T10:30:13.517589Z",
     "iopub.status.busy": "2024-08-10T10:30:13.517327Z",
     "iopub.status.idle": "2024-08-10T10:30:13.525673Z",
     "shell.execute_reply": "2024-08-10T10:30:13.525079Z"
    },
    "papermill": {
     "duration": 0.015064,
     "end_time": "2024-08-10T10:30:13.527337",
     "exception": false,
     "start_time": "2024-08-10T10:30:13.512273",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def percentage(mask):\n",
    "    return (np.sum(mask > 0) / mask.size) * 100\n",
    "def extract_patches(im_slide, ms_slide, level, size_mask , num_patches_needed):\n",
    "    f = int(ms_slide.level_downsamples[level])\n",
    "    size_scale = im_slide.level_dimensions[level][0] // ms_slide.level_dimensions[level][0]\n",
    "    coord_scale = im_slide.level_dimensions[0][0] // ms_slide.level_dimensions[level][0]\n",
    "    size_image = (size_mask[0] * size_scale, size_mask[1] * size_scale)\n",
    "    \n",
    "    ms_width, ms_height = ms_slide.level_dimensions[level]\n",
    "    \n",
    "    image_patches , l= [], []\n",
    "    for y_ms in range(0, ms_height, size_mask[1]):\n",
    "        for x_ms in range(0, ms_width, size_mask[0]):\n",
    "            l.append([x_ms , y_ms])\n",
    "    \n",
    "    count,used_indices =0, []\n",
    "    random.seed(42)\n",
    "\n",
    "    while count < num_patches_needed:\n",
    "        index = random.randint(0, len(l) - 1)\n",
    "        if index not in used_indices:\n",
    "            used_indices.append(index)\n",
    "            x_ms, y_ms = l[index][0] , l[index][1]\n",
    "            x_im, y_im = x_ms * coord_scale, y_ms * coord_scale\n",
    "            mask_patch = ms_slide.read_region((x_ms * f, y_ms * f), level, size_mask).convert(\"L\")\n",
    "            image_patch = im_slide.read_region((x_im, y_im), level, size_image).convert(\"RGB\")\n",
    "   \n",
    "            if (percentage(np.array(mask_patch))) > 50  and (percentage(np.array(mask_patch))) > 50:\n",
    "                image_patches.append(np.array(image_patch))\n",
    "                count+=1\n",
    "                if count == num_patches_needed:\n",
    "                    break\n",
    "        else:\n",
    "            continue\n",
    "    return  image_patches\n",
    "# a=extract_patches(openslide.OpenSlide(\"/kaggle/input/dddddddd/images/case_radboud_0002.tif\"), openslide.OpenSlide(\"/kaggle/input/dddddddd/masks/case_radboud_0002_tissue.tif\"), 1, (64,64) , 5)\n",
    "# print(np.shape(a))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "551bbbeb",
   "metadata": {
    "papermill": {
     "duration": 0.003894,
     "end_time": "2024-08-10T10:30:13.535446",
     "exception": false,
     "start_time": "2024-08-10T10:30:13.531552",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "995c16eb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-10T10:30:13.545223Z",
     "iopub.status.busy": "2024-08-10T10:30:13.544997Z",
     "iopub.status.idle": "2024-08-10T10:30:13.552739Z",
     "shell.execute_reply": "2024-08-10T10:30:13.552182Z"
    },
    "papermill": {
     "duration": 0.014462,
     "end_time": "2024-08-10T10:30:13.554282",
     "exception": false,
     "start_time": "2024-08-10T10:30:13.539820",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PatchDataset(tf.keras.utils.Sequence):\n",
    "    def __init__(self, images_dir, masks_dir, csv_file, num_patches_per_image, level, size_mask, batch_size):\n",
    "        self.images_dir = images_dir\n",
    "        self.masks_dir = masks_dir\n",
    "        self.df = pd.read_csv(csv_file)\n",
    "        self.num_patches_per_image = num_patches_per_image\n",
    "        self.level = level\n",
    "        self.size_mask = size_mask\n",
    "        self.batch_size = batch_size\n",
    "        self.image_list = sorted(os.listdir(images_dir))\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.image_list) // self.batch_size\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        batch_images = []\n",
    "        batch_labels = []\n",
    "        \n",
    "        for i in range(self.batch_size):\n",
    "            image_file = self.image_list[idx * self.batch_size + i]\n",
    "            impath = os.path.join(self.images_dir, image_file)\n",
    "            mspath = os.path.join(self.masks_dir, image_file.replace('.tif', '_tissue.tif'))\n",
    "            \n",
    "            im_slide = openslide.OpenSlide(impath)\n",
    "            ms_slide = openslide.OpenSlide(mspath)\n",
    "            \n",
    "            image_patches = extract_patches(im_slide, ms_slide, self.level, self.size_mask, self.num_patches_per_image)\n",
    "            image_patches = np.array(image_patches, dtype=np.float32) \n",
    "            case_id_to_find = image_file\n",
    "            filtered_row = self.df.loc[self.df['case_id'] == case_id_to_find].iloc[0]\n",
    "            event = filtered_row[\"event\"]\n",
    "            years = filtered_row[\"follow_up_years\"]\n",
    "            \n",
    "            image_labels = [[event, years]] * self.num_patches_per_image\n",
    "            \n",
    "            batch_images.append(image_patches)\n",
    "            batch_labels.append(image_labels)\n",
    "        \n",
    "        return np.array(batch_images), np.array(batch_labels)\n",
    "    def repeat(self):\n",
    "        return self  # This allows the dataset to be used repeatedly\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "40dd6054",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-10T10:30:13.564008Z",
     "iopub.status.busy": "2024-08-10T10:30:13.563579Z",
     "iopub.status.idle": "2024-08-10T10:30:13.566483Z",
     "shell.execute_reply": "2024-08-10T10:30:13.565921Z"
    },
    "papermill": {
     "duration": 0.009724,
     "end_time": "2024-08-10T10:30:13.568202",
     "exception": false,
     "start_time": "2024-08-10T10:30:13.558478",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# images_dir = \"/kaggle/input/dddddddd/images\"\n",
    "# masks_dir = \"/kaggle/input/dddddddd/masks\"\n",
    "# csv_file = \"/kaggle/input/dddddddd/training_labels.csv\"\n",
    "\n",
    "# dataset = PatchDataset(images_dir, masks_dir, csv_file, num_patches_per_image=6, level=1, size_mask=(64, 64) ,batch_size= 11)\n",
    "# for a in dataset:\n",
    "#     x,y=a\n",
    "#     print(x.shape , y.shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9dd2777",
   "metadata": {
    "papermill": {
     "duration": 0.003917,
     "end_time": "2024-08-10T10:30:13.576252",
     "exception": false,
     "start_time": "2024-08-10T10:30:13.572335",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e1ae7603",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-10T10:30:13.585982Z",
     "iopub.status.busy": "2024-08-10T10:30:13.585729Z",
     "iopub.status.idle": "2024-08-10T10:30:13.597975Z",
     "shell.execute_reply": "2024-08-10T10:30:13.597288Z"
    },
    "papermill": {
     "duration": 0.018887,
     "end_time": "2024-08-10T10:30:13.599476",
     "exception": false,
     "start_time": "2024-08-10T10:30:13.580589",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DoubleConv(layers.Layer):\n",
    "    def __init__(self, filters):\n",
    "        super(DoubleConv, self).__init__()\n",
    "        self.conv1 = layers.Conv2D(filters, 3, padding='same')\n",
    "        self.bn1 = layers.BatchNormalization()\n",
    "        self.conv2 = layers.Conv2D(filters, 3, padding='same')\n",
    "        self.bn2 = layers.BatchNormalization()\n",
    "        self.relu = layers.ReLU()\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "\n",
    "class UNet(Model):\n",
    "    def __init__(self, num_patches , input_shape):\n",
    "        super(UNet, self).__init__()\n",
    "        self.num_patches = num_patches\n",
    "        self.input_shape = input_shape\n",
    "\n",
    "        self.inc = DoubleConv(64)\n",
    "        self.down1 = self.down_block(128)\n",
    "        self.down2 = self.down_block(256)\n",
    "        self.down3 = self.down_block(512)\n",
    "        self.down4 = self.down_block(1024)\n",
    "\n",
    "        self.up1 = self.up_block(512)\n",
    "        self.up2 = self.up_block(256)\n",
    "        self.up3 = self.up_block(128)\n",
    "        self.up4 = self.up_block(64)\n",
    "\n",
    "        self.gap = layers.GlobalAveragePooling2D()\n",
    "        self.fc1 = layers.Dense(32, activation='relu')\n",
    "        self.fc2 = layers.Dense(2)  # 2 outputs: event and years\n",
    "\n",
    "    def down_block(self, filters):\n",
    "        return tf.keras.Sequential([\n",
    "            layers.MaxPooling2D(2),\n",
    "            DoubleConv(filters)\n",
    "        ])\n",
    "\n",
    "    def up_block(self, filters):\n",
    "        return tf.keras.Sequential([\n",
    "            layers.Conv2DTranspose(filters, 2, strides=2, padding='same'),\n",
    "            DoubleConv(filters)\n",
    "        ])\n",
    "\n",
    "    def call(self, inputs):\n",
    "        batch_size = tf.shape(inputs)[0]\n",
    "        x = tf.reshape(inputs, [-1, self.input_shape[0], self.input_shape[1], self.input_shape[2]])\n",
    "\n",
    "        x1 = self.inc(x)\n",
    "        x2 = self.down1(x1)\n",
    "        x3 = self.down2(x2)\n",
    "        x4 = self.down3(x3)\n",
    "        x5 = self.down4(x4)\n",
    "\n",
    "        x = self.up1(x5)\n",
    "        x = tf.concat([x4, x], axis=-1)\n",
    "        x = self.up2(x)\n",
    "        x = tf.concat([x3, x], axis=-1)\n",
    "        x = self.up3(x)\n",
    "        x = tf.concat([x2, x], axis=-1)\n",
    "        x = self.up4(x)\n",
    "        x = tf.concat([x1, x], axis=-1)\n",
    "\n",
    "        x = self.gap(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        x = tf.reshape(x, [batch_size, self.num_patches, 2])\n",
    "\n",
    "        return x\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "29aafb16",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-10T10:30:13.608861Z",
     "iopub.status.busy": "2024-08-10T10:30:13.608596Z",
     "iopub.status.idle": "2024-08-10T10:30:13.611460Z",
     "shell.execute_reply": "2024-08-10T10:30:13.610871Z"
    },
    "papermill": {
     "duration": 0.00956,
     "end_time": "2024-08-10T10:30:13.613034",
     "exception": false,
     "start_time": "2024-08-10T10:30:13.603474",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model = UNet(num_patches=6 , input_shape=(512,512,3))\n",
    "# sample_input = tf.random.normal([2, 6, 512,512, 3])\n",
    "# output = model(sample_input)\n",
    "# print(output.shape)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59afbbd3",
   "metadata": {
    "papermill": {
     "duration": 0.004345,
     "end_time": "2024-08-10T10:30:13.621442",
     "exception": false,
     "start_time": "2024-08-10T10:30:13.617097",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# TPU SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d6dc31d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-10T10:30:13.631376Z",
     "iopub.status.busy": "2024-08-10T10:30:13.631152Z",
     "iopub.status.idle": "2024-08-10T10:30:22.392079Z",
     "shell.execute_reply": "2024-08-10T10:30:22.391178Z"
    },
    "papermill": {
     "duration": 8.768366,
     "end_time": "2024-08-10T10:30:22.394137",
     "exception": false,
     "start_time": "2024-08-10T10:30:13.625771",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1723285817.538762      77 service.cc:145] XLA service 0x5baaad8a7e10 initialized for platform TPU (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1723285817.538814      77 service.cc:153]   StreamExecutor device (0): TPU, 2a886c8\n",
      "I0000 00:00:1723285817.538819      77 service.cc:153]   StreamExecutor device (1): TPU, 2a886c8\n",
      "I0000 00:00:1723285817.538822      77 service.cc:153]   StreamExecutor device (2): TPU, 2a886c8\n",
      "I0000 00:00:1723285817.538825      77 service.cc:153]   StreamExecutor device (3): TPU, 2a886c8\n",
      "I0000 00:00:1723285817.538828      77 service.cc:153]   StreamExecutor device (4): TPU, 2a886c8\n",
      "I0000 00:00:1723285817.538831      77 service.cc:153]   StreamExecutor device (5): TPU, 2a886c8\n",
      "I0000 00:00:1723285817.538833      77 service.cc:153]   StreamExecutor device (6): TPU, 2a886c8\n",
      "I0000 00:00:1723285817.538836      77 service.cc:153]   StreamExecutor device (7): TPU, 2a886c8\n"
     ]
    }
   ],
   "source": [
    "resolver = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
    "tf.config.experimental_connect_to_cluster(resolver)\n",
    "tf.tpu.experimental.initialize_tpu_system(resolver)\n",
    "strategy = tf.distribute.TPUStrategy(resolver)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "57abe66d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-10T10:30:22.404993Z",
     "iopub.status.busy": "2024-08-10T10:30:22.404564Z",
     "iopub.status.idle": "2024-08-10T10:30:22.409785Z",
     "shell.execute_reply": "2024-08-10T10:30:22.409075Z"
    },
    "papermill": {
     "duration": 0.012578,
     "end_time": "2024-08-10T10:30:22.411309",
     "exception": false,
     "start_time": "2024-08-10T10:30:22.398731",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def epochnum(file):\n",
    "    try:\n",
    "        epoch_part = file.split('epoch')[1].split('-')[0]\n",
    "        return int(epoch_part)\n",
    "    except (IndexError, ValueError):\n",
    "        return -1\n",
    "    \n",
    "    \n",
    "    \n",
    "def custom_loss(y_true, y_pred):\n",
    "    mse = tf.keras.losses.MeanSquaredError()\n",
    "    \n",
    "    years_loss = mse(y_true[:, :, 1], y_pred[:, :, 1])\n",
    "    event_loss = mse(y_true[:, :, 0], y_pred[:, :, 0])\n",
    "\n",
    "    res,a=(1 * event_loss ), (1* years_loss)\n",
    "\n",
    "    return  res+a\n",
    "\n",
    "# print(custom_loss(output, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "afd298ac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-10T10:30:22.421465Z",
     "iopub.status.busy": "2024-08-10T10:30:22.421093Z",
     "iopub.status.idle": "2024-08-10T10:30:22.436349Z",
     "shell.execute_reply": "2024-08-10T10:30:22.435685Z"
    },
    "papermill": {
     "duration": 0.022413,
     "end_time": "2024-08-10T10:30:22.437953",
     "exception": false,
     "start_time": "2024-08-10T10:30:22.415540",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55\n"
     ]
    }
   ],
   "source": [
    "print(len(os.listdir(\"/kaggle/input/dddddddd/images\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e948f678",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-10T10:30:22.447910Z",
     "iopub.status.busy": "2024-08-10T10:30:22.447633Z",
     "iopub.status.idle": "2024-08-10T10:30:22.450972Z",
     "shell.execute_reply": "2024-08-10T10:30:22.450349Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.010061,
     "end_time": "2024-08-10T10:30:22.452572",
     "exception": false,
     "start_time": "2024-08-10T10:30:22.442511",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "            \n",
    "# BATCH_SIZE = 1\n",
    "# NUM_PATCHES = 4\n",
    "# INPUT_SHAPE = (512, 512, 3)\n",
    "# model = UNet(num_patches=NUM_PATCHES, input_shape=INPUT_SHAPE)\n",
    "# latest_checkpoint = \"/kaggle/working/epoch151-loss3.7436.weights.h5\"\n",
    "\n",
    "\n",
    "# sample_input = tf.zeros((1, NUM_PATCHES, INPUT_SHAPE[0], INPUT_SHAPE[1], INPUT_SHAPE[2]))\n",
    "# o = model(sample_input)\n",
    "# model.load_weights(latest_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "85053c59",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-10T10:30:22.462735Z",
     "iopub.status.busy": "2024-08-10T10:30:22.462333Z",
     "iopub.status.idle": "2024-08-10T10:30:22.465241Z",
     "shell.execute_reply": "2024-08-10T10:30:22.464606Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.009915,
     "end_time": "2024-08-10T10:30:22.466814",
     "exception": false,
     "start_time": "2024-08-10T10:30:22.456899",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# im=\"/kaggle/input/dddddddd/images/case_radboud_0217.tif\"\n",
    "# ms= \"/kaggle/input/dddddddd/masks/case_radboud_0217_tissue.tif\"\n",
    "# print(o.shape)\n",
    "# print(sample_input.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6eaf8717",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-10T10:30:22.477102Z",
     "iopub.status.busy": "2024-08-10T10:30:22.476853Z",
     "iopub.status.idle": "2024-08-10T10:30:22.480126Z",
     "shell.execute_reply": "2024-08-10T10:30:22.479431Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.010361,
     "end_time": "2024-08-10T10:30:22.481819",
     "exception": false,
     "start_time": "2024-08-10T10:30:22.471458",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# a=extract_patches(openslide.OpenSlide(im), openslide.OpenSlide(ms), 1, (64,64) , 4)\n",
    "# a = np.expand_dims(a, axis=0)  \n",
    "\n",
    "# a_tensor = tf.convert_to_tensor(a, dtype=tf.float32)\n",
    "\n",
    "# # print(type(a_tensor))\n",
    "# # print(a_tensor.shape)\n",
    "\n",
    "# out = model(a_tensor)\n",
    "# print(out.shape)\n",
    "# print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "234a0b96",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-10T10:30:22.492693Z",
     "iopub.status.busy": "2024-08-10T10:30:22.492272Z",
     "iopub.status.idle": "2024-08-10T10:30:22.495310Z",
     "shell.execute_reply": "2024-08-10T10:30:22.494642Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.010476,
     "end_time": "2024-08-10T10:30:22.496830",
     "exception": false,
     "start_time": "2024-08-10T10:30:22.486354",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# print(custom_loss(out, o))\n",
    "# print(custom_loss(out, out))\n",
    "# print(type(print(custom_loss(out, o))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "868b21c7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-10T10:30:22.507333Z",
     "iopub.status.busy": "2024-08-10T10:30:22.507096Z",
     "iopub.status.idle": "2024-08-10T10:30:22.510291Z",
     "shell.execute_reply": "2024-08-10T10:30:22.509598Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.010273,
     "end_time": "2024-08-10T10:30:22.511904",
     "exception": false,
     "start_time": "2024-08-10T10:30:22.501631",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "736d7c22",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-10T10:30:22.522560Z",
     "iopub.status.busy": "2024-08-10T10:30:22.522111Z",
     "iopub.status.idle": "2024-08-10T10:30:22.525675Z",
     "shell.execute_reply": "2024-08-10T10:30:22.525077Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.010908,
     "end_time": "2024-08-10T10:30:22.527230",
     "exception": false,
     "start_time": "2024-08-10T10:30:22.516322",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of TPU cores: 8\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of TPU cores: {strategy.num_replicas_in_sync}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4450b344",
   "metadata": {
    "papermill": {
     "duration": 0.004374,
     "end_time": "2024-08-10T10:30:22.536547",
     "exception": false,
     "start_time": "2024-08-10T10:30:22.532173",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# TRAINING "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f28b074",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-10T10:30:22.547591Z",
     "iopub.status.busy": "2024-08-10T10:30:22.547337Z",
     "iopub.status.idle": "2024-08-10T16:38:02.962071Z",
     "shell.execute_reply": "2024-08-10T16:38:02.961016Z"
    },
    "papermill": {
     "duration": 22060.422592,
     "end_time": "2024-08-10T16:38:02.964016",
     "exception": false,
     "start_time": "2024-08-10T10:30:22.541424",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "h5_files = [f for f in os.listdir(\"/kaggle/working\") if f.endswith('.h5')]\n",
    "resume=0\n",
    "if h5_files:\n",
    "    h5_files.sort(key=lambda x: epochnum(x), reverse=True)\n",
    "    num=epochnum(h5_files[0])\n",
    "    if num:\n",
    "        resume=num\n",
    "print(resume)\n",
    "\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "NUM_PATCHES = 4\n",
    "INPUT_SHAPE = (512, 512, 3)\n",
    "TOTAL_IMAGES = 55\n",
    "STEPS_PER_EPOCH =  (TOTAL_IMAGES + BATCH_SIZE - 1) // BATCH_SIZE\n",
    "\n",
    "\n",
    "numepochs=2002\n",
    "epochs=resume+numepochs\n",
    "\n",
    "\n",
    "images_dir = \"/kaggle/input/dddddddd/images\"\n",
    "masks_dir = \"/kaggle/input/dddddddd/masks\"\n",
    "csv_file = \"/kaggle/input/dddddddd/training_labels.csv\"\n",
    "checkpoint_dir = \"/kaggle/working\"\n",
    "\n",
    "# def lr_schedule(epoch, lr):\n",
    "#     initial_lr = 1e-3\n",
    "#     decay_rate = 0.9\n",
    "#     decay_steps = 30\n",
    "#     if epoch % decay_steps == 0 and epoch > 0:\n",
    "#         lr = lr * decay_rate\n",
    "#     return lr\n",
    "\n",
    "# # Define the LearningRateScheduler callback\n",
    "# lr_scheduler = keras.callbacks.LearningRateScheduler(lr_schedule, verbose=1)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='loss', factor=0.9, patience=3,verbose=True)\n",
    "\n",
    "\n",
    "class CustomCheckpoint(keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if epoch % 200 == 0:\n",
    "            self.model.save_weights(f\"{checkpoint_dir}/epoch{epoch+1:03d}-loss{logs['loss']:.4f}.weights.h5\")\n",
    "            print(f\" Model saved at epoch {epoch + 1}\")\n",
    "\n",
    "class CustomLogger(keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if epoch%50==0:\n",
    "            print(f\" Completed Epoch {epoch + 1}, Loss: {logs['loss']:.4f}\")\n",
    "\n",
    "\n",
    "def train_model(start_epoch=0, total_epochs=2):\n",
    "    dataset = PatchDataset(images_dir, masks_dir, csv_file, num_patches_per_image=NUM_PATCHES, level=1, size_mask=(64, 64), batch_size=BATCH_SIZE)\n",
    "    \n",
    "    with strategy.scope():\n",
    "        model = UNet(num_patches=NUM_PATCHES, input_shape=INPUT_SHAPE)\n",
    "        \n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate=1e-03)\n",
    "        \n",
    "\n",
    "\n",
    "        \n",
    "        h5_files = [f for f in os.listdir(checkpoint_dir) if f.endswith('.h5')]\n",
    "        if h5_files:\n",
    "            h5_files.sort(key=lambda x: epochnum(x), reverse=True)\n",
    "            latest_checkpoint = os.path.join(checkpoint_dir, h5_files[0])\n",
    "            print(f\"Resuming from checkpoint: {h5_files[0]}\")\n",
    "            try:\n",
    "                sample_input = tf.zeros((1, NUM_PATCHES, INPUT_SHAPE[0], INPUT_SHAPE[1], INPUT_SHAPE[2]))\n",
    "                nothing= model(sample_input)\n",
    "                model.load_weights(latest_checkpoint)\n",
    "                model.compile(optimizer=optimizer, loss=custom_loss)\n",
    "                total_params = model.count_params()\n",
    "                print(f\"Total number of parameters: {total_params:,}\")\n",
    "\n",
    "                start_epoch = epochnum(h5_files[0])\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading model: {e}\")\n",
    "                print(\"Starting from scratch.\")\n",
    "        else:\n",
    "            print(\"No checkpoint found. Starting from scratch.\")        \n",
    "        model.compile(optimizer=optimizer, loss=custom_loss)\n",
    "        history = model.fit(\n",
    "            dataset,\n",
    "            initial_epoch=start_epoch,\n",
    "            epochs=total_epochs,\n",
    "            steps_per_epoch=STEPS_PER_EPOCH,\n",
    "            verbose=1,\n",
    "            callbacks=[CustomCheckpoint(), CustomLogger(), reduce_lr]\n",
    "        )\n",
    "    \n",
    "    return history, model\n",
    "\n",
    "try:\n",
    "    history, trained_model = train_model(total_epochs=epochs)\n",
    "    print(\"Training complete.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred during training: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "730e654b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-10T16:38:04.216908Z",
     "iopub.status.busy": "2024-08-10T16:38:04.216534Z",
     "iopub.status.idle": "2024-08-10T16:38:04.222314Z",
     "shell.execute_reply": "2024-08-10T16:38:04.221405Z"
    },
    "papermill": {
     "duration": 0.621371,
     "end_time": "2024-08-10T16:38:04.223870",
     "exception": false,
     "start_time": "2024-08-10T16:38:03.602499",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "path = \"/kaggle/working\"\n",
    "pth_files = [f for f in os.listdir(path) if os.path.isfile(os.path.join(path, f)) and f.endswith('.h5')]\n",
    "pth_files.sort(key=lambda x: epochnum(x) , reverse=True)\n",
    "# for file in pth_files[1:]:\n",
    "#     os.remove(os.path.join(path , file))\n",
    "#     print(f\"removed {file}\")\n",
    "# print(os.listdir(path))\n",
    "# print(pth_files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e9fee5a2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-10T16:38:05.420044Z",
     "iopub.status.busy": "2024-08-10T16:38:05.419649Z",
     "iopub.status.idle": "2024-08-10T16:38:05.423466Z",
     "shell.execute_reply": "2024-08-10T16:38:05.422614Z"
    },
    "papermill": {
     "duration": 0.592509,
     "end_time": "2024-08-10T16:38:05.425115",
     "exception": false,
     "start_time": "2024-08-10T16:38:04.832606",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# os.remove(f\"{path}/state.db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d8b0d09d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-10T16:38:06.705570Z",
     "iopub.status.busy": "2024-08-10T16:38:06.704736Z",
     "iopub.status.idle": "2024-08-10T16:38:06.708605Z",
     "shell.execute_reply": "2024-08-10T16:38:06.707708Z"
    },
    "papermill": {
     "duration": 0.635109,
     "end_time": "2024-08-10T16:38:06.710329",
     "exception": false,
     "start_time": "2024-08-10T16:38:06.075220",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# print(os.listdir(path))"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "tpu1vmV38",
   "dataSources": [
    {
     "datasetId": 5427593,
     "sourceId": 9022641,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30748,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 22110.802653,
   "end_time": "2024-08-10T16:38:17.558320",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-08-10T10:29:46.755667",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
