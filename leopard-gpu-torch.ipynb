{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":9008752,"sourceType":"datasetVersion","datasetId":5397808},{"sourceId":9022641,"sourceType":"datasetVersion","datasetId":5427593}],"dockerImageVersionId":30747,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!apt-get install  -y openslide-tools\n!pip install openslide-python pillow \n# !pip install --upgrade pip \n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-07-25T16:33:35.258738Z","iopub.execute_input":"2024-07-25T16:33:35.259077Z","iopub.status.idle":"2024-07-25T16:33:51.447364Z","shell.execute_reply.started":"2024-07-25T16:33:35.259051Z","shell.execute_reply":"2024-07-25T16:33:51.446400Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Reading package lists... Done\nBuilding dependency tree       \nReading state information... Done\nopenslide-tools is already the newest version (3.4.1+dfsg-4).\n0 upgraded, 0 newly installed, 0 to remove and 80 not upgraded.\nRequirement already satisfied: openslide-python in /opt/conda/lib/python3.10/site-packages (1.3.1)\nRequirement already satisfied: pillow in /opt/conda/lib/python3.10/site-packages (9.5.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np\nfrom PIL import Image\nimport openslide\nimport matplotlib.pyplot as plt\nimport random\nimport pandas as pd\nimport os\n\nimport time \nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.nn.parallel import DataParallel\n","metadata":{"execution":{"iopub.status.busy":"2024-07-25T16:33:51.449842Z","iopub.execute_input":"2024-07-25T16:33:51.450556Z","iopub.status.idle":"2024-07-25T16:33:55.151338Z","shell.execute_reply.started":"2024-07-25T16:33:51.450519Z","shell.execute_reply":"2024-07-25T16:33:55.150362Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"def percentage(mask):\n    return (np.sum(mask > 0) / mask.size) * 100\ndef extract_patches(im_slide, ms_slide, level, size_mask , num_patches_needed):\n    f = int(ms_slide.level_downsamples[level])\n    size_scale = im_slide.level_dimensions[level][0] // ms_slide.level_dimensions[level][0]\n    coord_scale = im_slide.level_dimensions[0][0] // ms_slide.level_dimensions[level][0]\n    size_image = (size_mask[0] * size_scale, size_mask[1] * size_scale)\n    \n    ms_width, ms_height = ms_slide.level_dimensions[level]\n    \n    image_patches , l= [], []\n    for y_ms in range(0, ms_height, size_mask[1]):\n        for x_ms in range(0, ms_width, size_mask[0]):\n            l.append([x_ms , y_ms])\n    \n    count,used_indices =0, []\n\n    while count < num_patches_needed:\n        index = random.randint(0, len(l) - 1)\n        if index not in used_indices:\n            used_indices.append(index)\n            x_ms, y_ms = l[index][0] , l[index][1]\n            x_im, y_im = x_ms * coord_scale, y_ms * coord_scale\n            mask_patch = ms_slide.read_region((x_ms * f, y_ms * f), level, size_mask).convert(\"L\")\n            image_patch = im_slide.read_region((x_im, y_im), level, size_image).convert(\"RGB\")\n   \n            if (percentage(np.array(mask_patch))) > 30:\n                image_patches.append(np.array(image_patch))\n                count+=1\n                if count == num_patches_needed:\n                    break\n        else:\n            continue\n    return  image_patches","metadata":{"execution":{"iopub.status.busy":"2024-07-25T16:33:55.152493Z","iopub.execute_input":"2024-07-25T16:33:55.152910Z","iopub.status.idle":"2024-07-25T16:33:55.164076Z","shell.execute_reply.started":"2024-07-25T16:33:55.152884Z","shell.execute_reply":"2024-07-25T16:33:55.163202Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# path = \"/kaggle/input/datasetfour/mask/case_radboud_0000_tissue.tif\"\n# path1 = \"/kaggle/input/datasetfour/image/case_radboud_0000.tif\"\n\n# im_slide = openslide.OpenSlide(path1)\n# ms_slide = openslide.OpenSlide(path)\n\n# level = 1\n# size_mask = (128,128)\n# num_patches_needed=5\n# im= extract_patches(im_slide, ms_slide, level, size_mask , num_patches_needed)\n# print(np.shape(im))\n","metadata":{"execution":{"iopub.status.busy":"2024-07-25T16:33:55.166150Z","iopub.execute_input":"2024-07-25T16:33:55.166450Z","iopub.status.idle":"2024-07-25T16:33:55.172333Z","shell.execute_reply.started":"2024-07-25T16:33:55.166425Z","shell.execute_reply":"2024-07-25T16:33:55.171699Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-07-25T16:33:55.173559Z","iopub.execute_input":"2024-07-25T16:33:55.174173Z","iopub.status.idle":"2024-07-25T16:33:55.237649Z","shell.execute_reply.started":"2024-07-25T16:33:55.174140Z","shell.execute_reply":"2024-07-25T16:33:55.236763Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Using device: cuda\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# **DATASET**","metadata":{}},{"cell_type":"code","source":"class PatchData(Dataset):\n    def __init__(self, images, masks, csv_file, num_patches_per_image, level, size_mask):\n        self.images_dir = images\n        self.masks_dir = masks\n        self.num_patches_per_image = num_patches_per_image\n        self.level = level\n        self.size_mask = size_mask\n        \n        self.image_list = sorted(os.listdir(self.images_dir))\n        self.mask_list = sorted(os.listdir(self.masks_dir))\n        \n        self.df = pd.read_csv(csv_file)\n        \n    def __getitem__(self, index):\n        # Fetch the image and mask for the current index\n        image_file = self.image_list[index]\n        impath = os.path.join(self.images_dir, image_file)\n        mspath = os.path.join(self.masks_dir, image_file.replace('.tif', '_tissue.tif'))\n        \n        im_slide = openslide.OpenSlide(impath)\n        ms_slide = openslide.OpenSlide(mspath)\n        \n        # Extract patches from the image\n        image_patches = extract_patches(im_slide, ms_slide, self.level, self.size_mask, self.num_patches_per_image)\n        \n        # Find corresponding data in CSV\n        case_id_to_find = image_file  # Keep the .tif extension\n        filtered_row = self.df.loc[self.df['case_id'] == case_id_to_find].iloc[0]\n        event = filtered_row[\"event\"]\n        years = filtered_row[\"follow_up_years\"]\n        \n        # Create labels for each patch\n        image_labels = [[event, years]] * self.num_patches_per_image\n        \n        # Convert to tensors\n        patches_x = torch.tensor(np.array(image_patches), dtype=torch.float32)\n        data_y = torch.tensor(np.array(image_labels), dtype=torch.float32)\n        \n        return patches_x, data_y\n    \n    def __len__(self):\n        # Number of images\n        return len(self.image_list)\n\n   ","metadata":{"execution":{"iopub.status.busy":"2024-07-25T16:33:55.239080Z","iopub.execute_input":"2024-07-25T16:33:55.239434Z","iopub.status.idle":"2024-07-25T16:33:55.251078Z","shell.execute_reply.started":"2024-07-25T16:33:55.239407Z","shell.execute_reply":"2024-07-25T16:33:55.250046Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":" \n    \n# images = \"/kaggle/input/datasetfour/image\"\n# masks = \"/kaggle/input/datasetfour/mask\"\n# csv_file = \"/kaggle/input/datasetfour/training_labels.csv\"\n# dataset = PatchData(images=images, \n#                     masks=masks, \n#                     csv_file=csv_file, \n#                     num_patches_per_image=5,  # Number of patches per image\n#                     level=1, \n#                     size_mask=(128, 128))\n# dataloader = DataLoader(dataset, batch_size=1, shuffle=True)\n\n# # Check shapes\n# for x, y in dataloader:\n#     print(\"Training shapes:\")\n#     print(f\"Input shape: {x.shape}\")\n#     print(f\"Label shape: {y.shape}\")","metadata":{"execution":{"iopub.status.busy":"2024-07-25T16:33:55.252313Z","iopub.execute_input":"2024-07-25T16:33:55.252655Z","iopub.status.idle":"2024-07-25T16:33:55.260369Z","shell.execute_reply.started":"2024-07-25T16:33:55.252629Z","shell.execute_reply":"2024-07-25T16:33:55.259610Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"> # **MODEL** ","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass DoubleConv(nn.Module):\n    def __init__(self, in_channels, out_channels):\n        super(DoubleConv, self).__init__()\n        self.conv = nn.Sequential(\n            nn.Conv2d(in_channels, out_channels, 3, padding=1),\n            nn.BatchNorm2d(out_channels),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(out_channels, out_channels, 3, padding=1),\n            nn.BatchNorm2d(out_channels),\n            nn.ReLU(inplace=True)\n        )\n\n    def forward(self, x):\n        return self.conv(x)\n\nclass UNet(nn.Module):\n    def __init__(self, in_channels, out_channels):\n\n\n        super(UNet, self).__init__()\n        self.in_channels = in_channels\n        self.out_channels = out_channels\n        self.inc = DoubleConv(in_channels, 64)\n        self.down1 = nn.Sequential(nn.MaxPool2d(2), DoubleConv(64, 128))\n        self.down2 = nn.Sequential(nn.MaxPool2d(2), DoubleConv(128, 256))\n        self.down3 = nn.Sequential(nn.MaxPool2d(2), DoubleConv(256, 512))\n        self.down4 = nn.Sequential(nn.MaxPool2d(2), DoubleConv(512, 1024))\n\n        self.up1 = nn.ConvTranspose2d(1024, 512, 2, stride=2)\n        self.up_conv1 = DoubleConv(1024, 512)\n        self.up2 = nn.ConvTranspose2d(512, 256, 2, stride=2)\n        self.up_conv2 = DoubleConv(512, 256)\n        self.up3 = nn.ConvTranspose2d(256, 128, 2, stride=2)\n        self.up_conv3 = DoubleConv(256, 128)\n        self.up4 = nn.ConvTranspose2d(128, 64, 2, stride=2)\n        self.up_conv4 = DoubleConv(128, 64)\n\n        self.outc = nn.Conv2d(64, out_channels, 1)\n\n        # Global Average Pooling and Fully Connected layers for patch-level predictions\n        self.gap = nn.AdaptiveAvgPool2d(1)\n        self.fc1 = nn.Linear(64, 32)\n        self.fc2 = nn.Linear(32, 2)  # 2 outputs: event and years\n\n    def forward(self, x):\n        # x shape: [batch_size, num_patches, height, width, channels]\n        batch_size, num_patches, height, width, channels = x.shape\n        x = x.view(batch_size * num_patches, channels, height, width)\n\n        x1 = self.inc(x)\n        x2 = self.down1(x1)\n        x3 = self.down2(x2)\n        x4 = self.down3(x3)\n        x5 = self.down4(x4)\n\n        x = self.up1(x5)\n        x = self.up_conv1(torch.cat([x4, x], dim=1))\n        x = self.up2(x)\n        x = self.up_conv2(torch.cat([x3, x], dim=1))\n        x = self.up3(x)\n        x = self.up_conv3(torch.cat([x2, x], dim=1))\n        x = self.up4(x)\n        x = self.up_conv4(torch.cat([x1, x], dim=1))\n\n        # Global Average Pooling and Fully Connected layers\n        x = self.gap(x)\n        x = x.view(batch_size * num_patches, -1)\n        x = F.relu(self.fc1(x))\n        x = self.fc2(x)\n\n        # Reshape output to match the input shape\n        x = x.view(batch_size, num_patches, 2)\n\n        return x","metadata":{"execution":{"iopub.status.busy":"2024-07-25T16:33:55.261671Z","iopub.execute_input":"2024-07-25T16:33:55.262003Z","iopub.status.idle":"2024-07-25T16:33:55.281402Z","shell.execute_reply.started":"2024-07-25T16:33:55.261973Z","shell.execute_reply":"2024-07-25T16:33:55.280483Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# device = xm.xla_device()\n# model = UNet(in_channels=3, out_channels=2).to(device)\n\n# # You can uncomment these lines if you want to test the model with random input\n# batch_size = 2\n# num_patches = 6\n# channels = 3\n# height = 1024\n# width = 1024\n# train_input = torch.randn(batch_size, num_patches, height, width, channels).to(device)\n# print(f\"Training input shape: {train_input.shape}\")\n# train_output = model(train_input)\n# print(f\"Training output shape: {train_output.shape}\")\n\n# # Calculate total parameters\n# total_params = sum(p.numel() for p in model.parameters())\n# print(f\"\\nTotal number of parameters: {total_params}\")","metadata":{"execution":{"iopub.status.busy":"2024-07-25T16:33:55.282419Z","iopub.execute_input":"2024-07-25T16:33:55.282693Z","iopub.status.idle":"2024-07-25T16:33:55.293380Z","shell.execute_reply.started":"2024-07-25T16:33:55.282670Z","shell.execute_reply":"2024-07-25T16:33:55.292456Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"model = UNet(in_channels=3, out_channels=2)\n\n# Use DataParallel if multiple GPUs are available\nif torch.cuda.device_count() > 1:\n    print(f\"Using {torch.cuda.device_count()} GPUs\")\n    model = DataParallel(model)\n\nmodel = model.to(device)\n\n# Dataset and DataLoader setup\nimages = \"/kaggle/input/dddddddd/images\"\nmasks = \"/kaggle/input/dddddddd/masks\"\ncsv_file = \"/kaggle/input/dddddddd/training_labels.csv\"\ndataset = PatchData(images=images, \n                    masks=masks, \n                    csv_file=csv_file, \n                    num_patches_per_image=3,  \n                    level=1, \n                    size_mask=(64, 64))\ndataloader = DataLoader(dataset, batch_size=8, shuffle=True, num_workers=4, pin_memory=True)\n\ncriterion = nn.MSELoss()\noptim = torch.optim.Adam(model.parameters(), lr=1e-2)\n\n# Create the scheduler\nscheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optim, factor=0.1, patience=1)\n\n","metadata":{"execution":{"iopub.status.busy":"2024-07-25T16:33:55.295958Z","iopub.execute_input":"2024-07-25T16:33:55.296328Z","iopub.status.idle":"2024-07-25T16:33:57.393074Z","shell.execute_reply.started":"2024-07-25T16:33:55.296303Z","shell.execute_reply":"2024-07-25T16:33:57.392301Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Using 2 GPUs\n","output_type":"stream"}]},{"cell_type":"code","source":"def epochnum(file):\n    start,end,s = 0,0,file\n    for i in range(len(s)):\n        if s[i] == \"h\":\n            start = i + 1\n            break\n    for i in range(len(s)):\n        if s[i] == \"-\":\n            end = i\n            break\n    return int(file[start:end])","metadata":{"execution":{"iopub.status.busy":"2024-07-25T16:33:57.394208Z","iopub.execute_input":"2024-07-25T16:33:57.394731Z","iopub.status.idle":"2024-07-25T16:33:57.401070Z","shell.execute_reply.started":"2024-07-25T16:33:57.394696Z","shell.execute_reply":"2024-07-25T16:33:57.399930Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"def train(model, optim, criterion, dataloader, epochs, device, start_epoch, scheduler):\n    model.train()\n\n    for epoch in range(start_epoch + 1, start_epoch + epochs + 1):\n        losses = 0\n        c = 0\n        for img, label in dataloader:\n            img, label = img.to(device), label.to(device)\n            optim.zero_grad()\n            out = model(img)\n\n            loss = criterion(out, label)\n            loss.backward()\n            optim.step()\n            losses += loss.item()\n            c += 1\n        \n        mean_loss = losses / c\n        scheduler.step(mean_loss)\n        \n        print(f\"epoch {epoch}, mean_loss {mean_loss:.4f} , total_loss {losses:.4f} \")\n        \n        if torch.cuda.device_count() == 1 or (torch.cuda.device_count() > 1 and torch.cuda.current_device() == 0):\n            model_filename = f\"epoch{epoch}-loss{mean_loss:.4f}.pth\"\n            model_path = os.path.join( \"/kaggle/working\", model_filename)\n            torch.save(model.state_dict(), model_path)\n            print(f\"Model saved: {model_path}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-07-25T16:33:57.402152Z","iopub.execute_input":"2024-07-25T16:33:57.402415Z","iopub.status.idle":"2024-07-25T16:33:57.410913Z","shell.execute_reply.started":"2024-07-25T16:33:57.402392Z","shell.execute_reply":"2024-07-25T16:33:57.410028Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"path = \"/kaggle/working\"\npth_files = [f for f in os.listdir(path) if os.path.isfile(os.path.join(path, f)) and f.endswith('.pth')]\npth_files.sort(key=lambda x: epochnum(os.path.join(path, x)), reverse=True)\n\nif pth_files:\n    state = pth_files[0]\n    weights = os.path.join(path, state)\n    print(f\"Resuming from checkpoint: {state}\")\n    print(f\"Loading weights from: {state}\")\n    model.load_state_dict(torch.load(weights, map_location='cpu'))\n    model.to(device)\n    \n    start_epoch = epochnum(state)\nelse:\n    print(\"No checkpoint found. Starting from scratch.\")\n    start_epoch = 0\n\nprint(f\"Starting from epoch: {start_epoch}\")\n\ntrain(model, optim, criterion, dataloader, epochs=2, device=device, start_epoch=start_epoch, scheduler=scheduler)\n","metadata":{"execution":{"iopub.status.busy":"2024-07-25T16:33:57.411980Z","iopub.execute_input":"2024-07-25T16:33:57.412235Z","iopub.status.idle":"2024-07-25T16:34:03.165837Z","shell.execute_reply.started":"2024-07-25T16:33:57.412212Z","shell.execute_reply":"2024-07-25T16:34:03.164074Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"No checkpoint found. Starting from scratch.\nStarting from epoch: 0\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)","Cell \u001b[0;32mIn[13], line 20\u001b[0m\n\u001b[1;32m     16\u001b[0m     start_epoch \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStarting from epoch: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstart_epoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 20\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstart_epoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscheduler\u001b[49m\u001b[43m)\u001b[49m\n","Cell \u001b[0;32mIn[12], line 10\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, optim, criterion, dataloader, epochs, device, start_epoch, scheduler)\u001b[0m\n\u001b[1;32m      8\u001b[0m img, label \u001b[38;5;241m=\u001b[39m img\u001b[38;5;241m.\u001b[39mto(device), label\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      9\u001b[0m optim\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 10\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(out, label)\n\u001b[1;32m     13\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/data_parallel.py:185\u001b[0m, in \u001b[0;36mDataParallel.forward\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodule(\u001b[38;5;241m*\u001b[39minputs[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodule_kwargs[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m    184\u001b[0m replicas \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreplicate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodule, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice_ids[:\u001b[38;5;28mlen\u001b[39m(inputs)])\n\u001b[0;32m--> 185\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparallel_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreplicas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodule_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgather(outputs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_device)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/data_parallel.py:200\u001b[0m, in \u001b[0;36mDataParallel.parallel_apply\u001b[0;34m(self, replicas, inputs, kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mparallel_apply\u001b[39m(\u001b[38;5;28mself\u001b[39m, replicas: Sequence[T], inputs: Sequence[Any], kwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[Any]:\n\u001b[0;32m--> 200\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparallel_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreplicas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_ids\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mreplicas\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:110\u001b[0m, in \u001b[0;36mparallel_apply\u001b[0;34m(modules, inputs, kwargs_tup, devices)\u001b[0m\n\u001b[1;32m    108\u001b[0m     output \u001b[38;5;241m=\u001b[39m results[i]\n\u001b[1;32m    109\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(output, ExceptionWrapper):\n\u001b[0;32m--> 110\u001b[0m         \u001b[43moutput\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    111\u001b[0m     outputs\u001b[38;5;241m.\u001b[39mappend(output)\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_utils.py:694\u001b[0m, in \u001b[0;36mExceptionWrapper.reraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    691\u001b[0m     \u001b[38;5;66;03m# If the exception takes multiple arguments, don't try to\u001b[39;00m\n\u001b[1;32m    692\u001b[0m     \u001b[38;5;66;03m# instantiate since we don't know how to\u001b[39;00m\n\u001b[1;32m    693\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 694\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception\n","\u001b[0;31mOutOfMemoryError\u001b[0m: Caught OutOfMemoryError in replica 0 on device 0.\nOriginal Traceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py\", line 85, in _worker\n    output = module(*input, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/tmp/ipykernel_34/2476886095.py\", line 67, in forward\n    x = self.up_conv4(torch.cat([x1, x], dim=1))\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/tmp/ipykernel_34/2476886095.py\", line 18, in forward\n    return self.conv(x)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/container.py\", line 215, in forward\n    input = module(input)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/conv.py\", line 460, in forward\n    return self._conv_forward(input, self.weight, self.bias)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/conv.py\", line 456, in _conv_forward\n    return F.conv2d(input, weight, bias, self.stride,\ntorch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 768.00 MiB. GPU 0 has a total capacty of 14.74 GiB of which 214.12 MiB is free. Process 2267 has 14.53 GiB memory in use. Of the allocated memory 13.24 GiB is allocated by PyTorch, and 1.09 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n"],"ename":"OutOfMemoryError","evalue":"Caught OutOfMemoryError in replica 0 on device 0.\nOriginal Traceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py\", line 85, in _worker\n    output = module(*input, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/tmp/ipykernel_34/2476886095.py\", line 67, in forward\n    x = self.up_conv4(torch.cat([x1, x], dim=1))\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/tmp/ipykernel_34/2476886095.py\", line 18, in forward\n    return self.conv(x)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/container.py\", line 215, in forward\n    input = module(input)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/conv.py\", line 460, in forward\n    return self._conv_forward(input, self.weight, self.bias)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/conv.py\", line 456, in _conv_forward\n    return F.conv2d(input, weight, bias, self.stride,\ntorch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 768.00 MiB. GPU 0 has a total capacty of 14.74 GiB of which 214.12 MiB is free. Process 2267 has 14.53 GiB memory in use. Of the allocated memory 13.24 GiB is allocated by PyTorch, and 1.09 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","output_type":"error"}]},{"cell_type":"code","source":"path = \"/kaggle/working\"\npth_files = [f for f in os.listdir(path) if os.path.isfile(os.path.join(path, f)) and f.endswith('.pth')]\npth_files.sort(key=lambda x: epochnum(os.path.join(path, x)) , reverse=True)\nfor file in pth_files[1:]:\n    os.remove(os.path.join(path , file))\n    print(f\"removed {file}\")","metadata":{"execution":{"iopub.status.busy":"2024-07-23T18:28:53.220034Z","iopub.execute_input":"2024-07-23T18:28:53.220434Z","iopub.status.idle":"2024-07-23T18:28:53.248791Z","shell.execute_reply.started":"2024-07-23T18:28:53.220404Z","shell.execute_reply":"2024-07-23T18:28:53.247773Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"removed epoch19-loss0.2804.pth\n","output_type":"stream"}]},{"cell_type":"code","source":"pth_files = [f for f in os.listdir(path) if os.path.isfile(os.path.join(path, f)) and f.endswith('.pth')]\nprint(pth_files)","metadata":{"execution":{"iopub.status.busy":"2024-07-23T18:16:56.952022Z","iopub.execute_input":"2024-07-23T18:16:56.952404Z","iopub.status.idle":"2024-07-23T18:16:56.958232Z","shell.execute_reply.started":"2024-07-23T18:16:56.952368Z","shell.execute_reply":"2024-07-23T18:16:56.957221Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !nvidia-smi\ntorch.cuda.empty_cache()","metadata":{"execution":{"iopub.status.busy":"2024-07-25T16:32:53.413725Z","iopub.execute_input":"2024-07-25T16:32:53.414560Z","iopub.status.idle":"2024-07-25T16:32:53.418668Z","shell.execute_reply.started":"2024-07-25T16:32:53.414527Z","shell.execute_reply":"2024-07-25T16:32:53.417726Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"!rm -rf /kaggle/working/*\n","metadata":{"execution":{"iopub.status.busy":"2024-07-23T13:23:55.518312Z","iopub.execute_input":"2024-07-23T13:23:55.519303Z","iopub.status.idle":"2024-07-23T13:23:56.241196Z","shell.execute_reply.started":"2024-07-23T13:23:55.519267Z","shell.execute_reply":"2024-07-23T13:23:56.239816Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.cuda.empty_cache()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(a.shape , b.shape)","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n# Assuming 'im' is a list or array where im[0] is an image\n# Adjust the figsize to your desired size (width, height in inches)\nplt.figure(figsize=(10, 10))\nplt.imshow(im[0])\nplt.axis('off') \nplt.show()","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mask_patches, image_patches = extract_patches(im_slide, ms_slide, level, size_mask)\n\nprint(f\"Number of mask patches: {len(mask_patches)}\")\nprint(f\"Number of image patches: {len(image_patches)}\")\n\n# Stitch patches\nstitched_mask = stitch_patches(mask_patches, size_mask, ms_slide.level_dimensions[level] , \"L\")\nsize_scale = im_slide.level_dimensions[level][0] // ms_slide.level_dimensions[level][0]\n\nsize_image = (size_mask[0] * size_scale, size_mask[1] * size_scale)\nstitched_image = stitch_patches(image_patches, size_image, im_slide.level_dimensions[level]  , \"RGB\")\nprint(size_image)\n# Display stitched images\nplt.figure(figsize=(20, 10))\nplt.subplot(1, 2, 1)\nplt.imshow(stitched_mask, cmap='gray')\nplt.title('Stitched Mask')\nplt.subplot(1, 2, 2)\nplt.imshow(stitched_image)\nplt.title('Stitched Image')\nplt.show()\n\n# Verify dimensions\nprint(f\"Stitched mask dimensions: {stitched_mask.size}\")\nprint(f\"Stitched image dimensions: {stitched_image.size}\")\nprint(f\"Original mask dimensions at level {level}: {ms_slide.level_dimensions[level]}\")\nprint(f\"Original image dimensions at level {level}: {im_slide.level_dimensions[level]}\")\n\n# Display a sample patch pair\nsample_index = 0  # You can change this to view different patches\nplt.figure(figsize=(10, 5))\nplt.subplot(1, 2, 1)\nplt.imshow(mask_patches[sample_index], cmap='gray')\nplt.title('Sample Mask Patch')\nplt.subplot(1, 2, 2)\nplt.imshow(image_patches[sample_index])\nplt.title('Corresponding Image Patch')\nplt.show()","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(np.shape(image_patches))\nprint(type(image_patches))","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!rm -rf /kaggle/working/*","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def stitch_patches(patches, patch_size, level_dims,mode):\n    stitched_image = Image.new(mode, level_dims)\n    x_offset = 0\n    y_offset = 0\n    for patch in patches:\n        stitched_image.paste(Image.fromarray(patch), (x_offset, y_offset) )\n        x_offset += patch_size[0]\n        if x_offset >= level_dims[0]:\n            x_offset = 0\n            y_offset += patch_size[1]\n    return stitched_image","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nfrom skimage import measure\nfrom scipy import ndimage\n\ndef extract_mask_features(mask):\n    \n    mask = (mask > 0).astype(int)\n    features = {}\n    \n    features['total_pixels'] = mask.size\n    features['positive_pixels'] = np.sum(mask)\n    features['negative_pixels'] = features['total_pixels'] - features['positive_pixels']\n    features['positive_percentage'] = features['positive_pixels'] / features['total_pixels'] * 100\n\n    labeled_mask, num_components = ndimage.label(mask)\n    features['num_components'] = num_components\n\n    regions = measure.regionprops(labeled_mask)\n    \n    if regions:\n        areas = [region.area for region in regions]\n        features['mean_component_area'] = np.mean(areas)\n        features['max_component_area'] = np.max(areas)\n        features['min_component_area'] = np.min(areas)\n        \n        perimeters = [region.perimeter for region in regions]\n        features['mean_component_perimeter'] = np.mean(perimeters)\n        features['max_component_perimeter'] = np.max(perimeters)\n        features['min_component_perimeter'] = np.min(perimeters)\n        \n        eccentricities = [region.eccentricity for region in regions]\n        features['mean_eccentricity'] = np.mean(eccentricities)\n        \n        solidities = [region.solidity for region in regions]\n        features['mean_solidity'] = np.mean(solidities)\n\n    edges = ndimage.sobel(mask)\n    features['edge_pixels'] = np.sum(edges > 0)\n    features['edge_to_area_ratio'] = features['edge_pixels'] / features['positive_pixels'] if features['positive_pixels'] > 0 else 0\n\n    return features\n\nmask = np.array(slide.read_region((0,0), level, size).convert(\"L\"))\nfeatures = extract_mask_features(mask)\nprint(features)","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nfrom skimage import measure\nfrom scipy import ndimage\n\nmask = np.array([\n    [0, 1, 1, 0, 0],\n    [0, 1, 1, 0, 0],\n    [0, 0, 0, 1, 1],\n    [0, 0, 0, 1, 1],\n    [0,0, 0, 1, 1]\n])\n\nprint(\"Original mask:\")\nprint(mask)","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labeled_mask, num_components = ndimage.label(mask)\nprint(\"\\nLabeled mask:\")\nprint(labeled_mask)\nprint(f\"Number of components: {num_components}\")\n\nregions = measure.regionprops(labeled_mask)\n","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"areas = [region.area for region in regions]\nprint(\"\\nAreas:\", areas)\nprint(\"Mean area:\", np.mean(areas))\nprint(\"Max area:\", np.max(areas))\nprint(\"Min area:\", np.min(areas))","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"perimeters = [region.perimeter for region in regions]\nprint(\"\\nPerimeters:\", perimeters)\nprint(\"Mean perimeter:\", np.mean(perimeters))\nprint(\"Max perimeter:\", np.max(perimeters))\nprint(\"Min perimeter:\", np.min(perimeters))","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"eccentricities = [region.eccentricity for region in regions]\nprint(\"\\nEccentricities:\", eccentricities)\nprint(\"Mean eccentricity:\", np.mean(eccentricities))","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"solidities = [region.solidity for region in regions]\nprint(\"\\nSolidities:\", solidities)\nprint(\"Mean solidity:\", np.mean(solidities))","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"edges = ndimage.sobel(mask)\nprint(edges)\nedge_mask = edges > 0\nprint(\"\\nEdge mask:\")\nprint(edge_mask)\nprint(mask)\nprint(\"Edge pixels:\", np.sum(edge_mask))\nprint(\"Edge to area ratio:\", np.sum(edge_mask) / np.sum(mask))","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]}]}